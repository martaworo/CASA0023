[
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "Remote sensors. Test\nXYSZ\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "CASA0023 Remote Sensing - Learning Diary",
    "section": "",
    "text": "Introduction\nHello!\nMy name is Marta, I am currently pursuing a master degree of Social and Geographic Data Science. My hallmark is the global outlook which I developed while studying and working in Chile, Spain, Poland and the UK. Coming from management, economics and finance background, I am happy to return to academia, aiming to leverage my practical experience in making a wider societal impact.\n\n\n\nSource: https://www.instagram.com/p/C3GfvH1OiFk/"
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "3  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "week2.html",
    "href": "week2.html",
    "title": "2  Week 2",
    "section": "",
    "text": "Xaringan Presentation\nThis week content is a presentation in Xaringan on the selected sensor. Summary, application and reflection are all included in the presentation below:"
  },
  {
    "objectID": "week1.html",
    "href": "week1.html",
    "title": "1  Week 1",
    "section": "",
    "text": "Getting started with remote sensing"
  },
  {
    "objectID": "week4.html",
    "href": "week4.html",
    "title": "4  Week 4",
    "section": "",
    "text": "Policy"
  },
  {
    "objectID": "week3.html",
    "href": "week3.html",
    "title": "3  Week 3",
    "section": "",
    "text": "Corrections"
  },
  {
    "objectID": "week1.html#summary",
    "href": "week1.html#summary",
    "title": "1  Week 1",
    "section": "1.1 Summary",
    "text": "1.1 Summary\n\n1.1.1 What is remote sensing?\nRemote sensing can be concluded as acquiring information from a distance which can be obtained via sensors. Remote sensors are devices that make use of the electromagnetic spectrum (Figure 1) and atmospheric transmission windows in order to observe a chosen target. Most remote sensors measure either an intensity change or a phase change of EM radiation.\n\n\n\nFigure 1. Simplified representation of the electromagnetic spectrum\n\n\nSensors can be divided into active and passive. Passive sensors detect natural energy emitted or reflected by the Earth, for example, optical sensors which are able to capture sunlight reflection (Figure 2a), while active sensors emit energy and measure the reflected or backscattered signals (Figure 2b). This wide range of sensors enables remote sensing data to be acquired via satellites for global coverage, aircraft for higher spatial resolution, and even drones for small-scale data collection.\n\n\n\nFigure 2. (a) Passive remote sensing: the sensor receives information. (b) Active remote sensing: the sensor emits and receives information.\n\n\n\n\n1.1.2 Scattering\nAtmospheric scattering occurs when the particles or gaseous molecules present in the atmosphere cause the EM radiation to be redirected from its original path. The amount of scattering depends on several factors including the wavelength of the radiation, the amount of particles and gases, and the distance the radiant energy travels through the atmosphere. Three types of scattering:\n-Rayleigh scattering – electromagnetic radiation interacts with particles that are smaller than the wavelengths of light -&gt; it disturbs RS in the visible spectral range from high altitudes. Due to Rayleigh scattering the shorter wavelengths are overestimated. It diminishes the ‘crispness’ of photos -&gt; has a negative effect on digital classification using data from multispectral sensors.\n-Mie scattering – occurs when the wavelength of the EM radiation is similar in size to the atmospheric particles (e.g. aerosols, a mixture of gases, water vapour, dust). Influences the spectral range from near-UV up to mid-IR, and has a greater effect on radiation of longer wavelengths than Rayleigh scattering\n-Non-selective scattering – occurs when the particle size is much larger than the radiation wavelength. For example, water droplets and larger dust particles. The most characteristic example is that we see clouds as white bodies. Important: clouds pose a great limitation – remote sensors cannot see through them, and they cast shadows.\nSince electromagnetic energy is partly absorbed by various molecules in the atmosphere, such as ozone, water vapour, and carbon dioxide, it may be concluded that many of the wavelengths are not useful for remote sensing of Earth’s surface, due to the corresponding energy not being able to penetrate the atmosphere. According to Tempfli et al. (2009) only the spectrum portions can be used for remote sensing, they are referred to as atmospheric transmission windows."
  },
  {
    "objectID": "week1.html#applications",
    "href": "week1.html#applications",
    "title": "1  Week 1",
    "section": "1.2 Applications",
    "text": "1.2 Applications\nDue to solar energy being reflected differently based on surface characteristics, remote sensors are able to collect information which can reflect characteristics of vegetation since its properties can be detected due to differences in energy reflection (Ashraf et al. 2011). The amount of energy reflected for a particular wavelength depends on leaf pigmentation, leaf thickness and composition (cell structure), and on the amount of water in the leaf tissue. Optical remote sensing can provide information about the type of plant and about its health condition. Or even forest biodervisity can be tracked with the use of remote sensors which are able to provide detailed information on key leaf traits such as leaf mass per area (wow!) (Gara, Rahimzadeh-Bajgiran, and Darvishzadeh 2021). Similarly, this can be applied for different types of soil too. For example, iron dominated soil has a significantly different reflectance curve, due to the iron absorption. This ‘feature’ of remote sensing can allow for detecion of soil contamination as Chen et al. (2024) did who in order to detect Chromium pollution used variability of soil spectra. Additionally, different forms of radiant energy allows to determine information regarding terrain surface (Poppiel et al. 2020). Wójtowicz, Wójtowicz, and Piekarczyk (2016) presented how to optimize profitability of agricultural crop production with the use of remote sensors. This capability can be especially beneficial for farmers allowing them to make informed decisions optimizing agricultural practices. However, as it has been pointed by Jensen et al. (2009), remote sensing data analysis might be costly, and require some expert knowledge. For this reason, not all farmers, as in the outlined case, would be able to benefit from this opportunity. Perhaps, only the biggest farming corporations are able to benefit of such practices."
  },
  {
    "objectID": "week1.html#reflection",
    "href": "week1.html#reflection",
    "title": "1  Week 1",
    "section": "1.3 Reflection",
    "text": "1.3 Reflection\nThe most interesting and life-changing part of this lecture was finally getting an answer to the biggest question of my life, why the sky is blue during a day, and orange/red during a sunset. Answer lies in scattering of sunlight. Due to difference in wave sizes, blue light is visible since it travels as shorter and smaller waves. This changes when the Sun gets lower in the sky, its light passes through more of the atmosphere, allowing the reds and yellows to pass straight through to our eyes.\nAnother interesting realization is the amount of objects located in the atmosphere. This raises questions whether there are sufficient policies in place that would regulate the amount of cluster, control its life cycle and ensuring suitable recycling or removal."
  },
  {
    "objectID": "week1.html#references",
    "href": "week1.html#references",
    "title": "1  Week 1",
    "section": "1.4 References",
    "text": "1.4 References\n\n\nAdeli, Sarina, Bahram Salehi, Masoud Mahdianpari, Lindi J. Quackenbush,\nBrian Brisco, Haifa Tamiminia, and Stephen Shaw. 2020. “Wetland\nMonitoring Using SAR\nData: A\nMeta-Analysis and Comprehensive\nReview.” Remote Sensing 12 (14): 2190. https://doi.org/10.3390/rs12142190.\n\n\nAshraf, Muhammad Aqeel, Mohd Jamil Maah, Ismail Yusoff, Muhammad Aqeel\nAshraf, Mohd Jamil Maah, and Ismail Yusoff. 2011. “Introduction to\nRemote Sensing of\nBiomass.” In Biomass and Remote\nSensing of Biomass. IntechOpen. https://doi.org/10.5772/16462.\n\n\nChen, Lihan, Kun Tan, Xue Wang, and Yu Chen. 2024. “A Rapid Soil\nChromium Pollution Detection Method Based on Hyperspectral\nRemote Sensing Data.” International Journal of Applied Earth\nObservation and Geoinformation 128 (April): 103759. https://doi.org/10.1016/j.jag.2024.103759.\n\n\nDou, Peng, Huanfeng Shen, Zhiwei Li, Xiaobin Guan, and Wenli Huang.\n2021. “Remote Sensing Image\nClassification Using\nDeep–Shallow Learning.”\nIEEE Journal of Selected Topics in Applied Earth Observations and\nRemote Sensing 14 (January): 3070–83. https://doi.org/10.1109/JSTARS.2021.3062635.\n\n\nFekri, Erfan, Hooman Latifi, Meisam Amani, and Abdolkarim Zobeidinezhad.\n2021. “A Training Sample\nMigration Method for Wetland\nMapping and Monitoring Using\nSentinel Data in Google\nEarth Engine.” Remote Sensing\n13 (20): 4169. https://doi.org/10.3390/rs13204169.\n\n\nFeng, Fukang, Maofang Gao, Ronghua Liu, Shuihong Yao, and Guijun Yang.\n2023. “A Deep Learning Framework for Crop Mapping with\nReconstructed Sentinel-2 Time Series Images.”\nComputers and Electronics in Agriculture 213 (October): 108227.\nhttps://doi.org/10.1016/j.compag.2023.108227.\n\n\nGara, Tawanda W., Parinaz Rahimzadeh-Bajgiran, and Roshanak\nDarvishzadeh. 2021. “Forest Leaf Mass\nPer Area (LMA) Through the Eye of\nOptical Remote Sensing:\nA Review and Future\nOutlook.” Remote Sensing 13 (17): 3352. https://doi.org/10.3390/rs13173352.\n\n\nGorelick, Noel, Matt Hancher, Mike Dixon, Simon Ilyushchenko, David\nThau, and Rebecca Moore. 2017. “Google Earth\nEngine: Planetary-Scale Geospatial Analysis\nfor Everyone.” Remote Sensing of Environment, Big\nRemotely Sensed Data: Tools,\napplications and experiences, 202 (December): 18–27. https://doi.org/10.1016/j.rse.2017.06.031.\n\n\nGroup, World Bank. 2019. “Air Quality in Poland, What Are the\nIssues and What Can Be Done?” September.\n\n\nJensen, Ryan R., Perry J. Hardin, Matthew Bekker, Derek S. Farnes, Vijay\nLulla, and Andrew Hardin. 2009. “Modeling Urban Leaf Area Index\nwith AISA+ Hyperspectral Data.” Applied\nGeography 29 (3): 320–32. https://doi.org/10.1016/j.apgeog.2008.10.001.\n\n\nLi, Ying, and Cheng Bo. 2009. “Research on Automatic\nOptimization of Ground Control\nPoints in Image Geometric\nRectification Based on Voronoi\nDiagram,” October. https://doi.org/10.1117/12.813148.\n\n\nLin, Shuyuan, Feiran Huang, Taotao Lai, Jianhuang Lai, Hanzi Wang, and\nJian Weng. 2024. “Robust Heterogeneous\nModel Fitting for Multi-Source\nImage Correspondences.”\nInternational Journal of Computer Vision, February. https://doi.org/10.1007/s11263-024-02023-9.\n\n\nLucivero, Federica. 2020. “Big Data, Big\nWaste? A Reflection on the\nEnvironmental Sustainability of\nBig Data Initiatives.”\nScience and Engineering Ethics 26 (2): 1009–30. https://doi.org/10.1007/s11948-019-00171-7.\n\n\nMa, Jiayi, Xingyu Jiang, Aoxiang Fan, Junjun Jiang, and Junchi Yan.\n2021. “Image Matching from Handcrafted\nto Deep Features: A\nSurvey.” International Journal of Computer\nVision 129 (1): 23–79. https://doi.org/10.1007/s11263-020-01359-2.\n\n\nMontagnon, Tristan, James Hollingsworth, Erwan Pathier, Mathilde\nMarchandon, Mauro Dalla Mura, and Sophie Giffard-Roisin. 2022.\n“Sub-Pixel Optical Satellite\nImage Registration for Ground\nDeformation Using Deep\nLearning.” In 2022 IEEE\nInternational Conference on Image\nProcessing (ICIP), 2716–20. https://doi.org/10.1109/ICIP46576.2022.9897214.\n\n\nNguyen, Thanh. 2015. “Optimal Ground\nControl Points for Geometric\nCorrection Using Genetic\nAlgorithm with Global\nAccuracy.” European Journal of Remote\nSensing 48 (1): 101–20. https://doi.org/10.5721/EuJRS20154807.\n\n\nP.Dave, Chintan, Rahul Joshi, and S. Srivastava. 2015. “A\nSurvey on Geometric Correction of\nSatellite Imagery.” International\nJournal of Computer Applications 116 (April): 24–27. https://doi.org/10.5120/20389-2655.\n\n\nPoppiel, Raúl Roberto, Marilusa Pinto Coelho Lacerda, Rodnei Rizzo, José\nLucas Safanelli, Benito Roberto Bonfatti, Nélida Elizabet Quiñonez\nSilvero, and José Alexandre Melo Demattê. 2020. “Soil\nColor and Mineralogy Mapping\nUsing Proximal and Remote\nSensing in Midwest\nBrazil.” Remote Sensing 12 (7): 1197. https://doi.org/10.3390/rs12071197.\n\n\nSaba, Sumbal Bahar, Muhammad Ali, Mark van der Meijde, and Harald van\nder Werff. 2017. “Co-Seismic Landslides Automatic Detection on\nRegional Scale with Sub-Pixel Analysis of Multi Temporal High Resolution\nOptical Images: Application to Southwest of Port Au Prince,\nHaiti.” Journal of Himalayan Earth Sciences 50 (2):\n74–92.\n\n\nSaba, Sumbal Bahar, Muhammad Ali, Syed Ali Turab, Muhammad Waseem, and\nShah Faisal. 2023. “Comparison of Pixel, Sub-Pixel and\nObject-Based Image Analysis Techniques for Co-Seismic Landslides\nDetection in Seismically Active Area in Lesser\nHimalaya, Pakistan.” Natural\nHazards 115 (3): 2383–98. https://doi.org/10.1007/s11069-022-05642-y.\n\n\nSaba, Sumbal Bahar, Nimat Ullah Khattak, Muhammad Ali, Muhammad Waseem,\nSamina Siddiqui, Seema Anjum, and Syed Ali Turab. 2019.\n“Application of Sub-Pixel-Based Technique\n‘Orthorectification of Optically Sensed Images and Its\nCorrelation’ for Co-Seismic Landslide Detection and Its Accuracy\nModification Through the Integration of Various Masks.”\nJournal of Himalayan Earth Sciences 52 (1): 37–50.\n\n\nSTATISTA. 2021. “Motorization Rate in Poland\n2021.” Statista. https://www.statista.com/statistics/452094/poland-number-of-cars-per-1000-inhabitants/.\n\n\nTamiminia, Haifa, Bahram Salehi, Masoud Mahdianpari, Lindi Quackenbush,\nSarina Adeli, and Brian Brisco. 2020. “Google Earth\nEngine for Geo-Big Data Applications: A\nMeta-Analysis and Systematic Review.” ISPRS Journal of\nPhotogrammetry and Remote Sensing 164 (June): 152–70. https://doi.org/10.1016/j.isprsjprs.2020.04.001.\n\n\nTempfli, Klaus, G. C. Huurneman, Wim Bakker, L. L. F. Janssen, W. F.\nFeringa, Ambro Gieske, K. A. Grabmaier, et al. 2009. “Principles\nof Remote Sensing : An Introductory Textbook.” In, 56–85.\n\n\nWei, Peng, Huichun Ye, Shuting Qiao, Ronghao Liu, Chaojia Nie, Bingrui\nZhang, Lijuan Song, and Shanyu Huang. 2023. “Early Crop Mapping\nBased on Sentinel-2 Time-Series Data and the Random Forest\nAlgorithm.” Remote Sensing 15 (13): 3212. https://doi.org/10.3390/rs15133212.\n\n\nWilkinson, R., M. M. Mleczko, R. J. W. Brewin, K. J. Gaston, M. Mueller,\nJ. D. Shutler, X. Yan, and K. Anderson. 2024. “Environmental\nImpacts of Earth Observation Data in the Constellation and Cloud\nComputing Era.” Science of The Total Environment 909\n(January): 168584. https://doi.org/10.1016/j.scitotenv.2023.168584.\n\n\nWójtowicz, Marek, Andrzej Wójtowicz, and J. Piekarczyk. 2016.\n“Application of Remote Sensing Methods in Agriculture” 11\n(January): 31–50."
  },
  {
    "objectID": "week3.html#summary",
    "href": "week3.html#summary",
    "title": "3  Week 3",
    "section": "3.1 Summary",
    "text": "3.1 Summary\n\nGeometric correction – distortion due to wind, Earth rotation, etc. Points are identified in a satellite image, and true image, e.g. Open Street Map (true representation of Earth). Ground control point is this location in image X, and find it on image Y. Then linear regression with distorted image and with gold standard data is performed. From Gold to EO. The more control points, the lower the error will be.\nAtmospheric correction – distortion due to haze or scattering; adjacency effect – pixels bleeding into other pixels; two ways to remove effects of atmosphere:\n\nrelative - Dark object subtraction (DOS) or histogram adjustment; Psuedo-invariant Features (PIFs). o absolute (definitive) – done through atmospheric radiative transfer models or empirical line correction – using a field spectrometer, and the you do linear regression between these values. Path radiance (radiance reflected above the surface), atmospheric attenuation (absorption of EMR due to materials in atmosphere)\n\nOrthorectification correction – subset of georectification;\n\ngeorectification = giving coordinates to an image;\northorectification = removing distortions… making the pixels viewed at nadir (straight down)\n\n\nAtmospheric correction has to be done before topographic correction Radiometric Calibration - sensors capture image brightness and distributed as a Digital Number (or DN) - allows for efficient storage but has no units! Sensor calibration = linear regression;\nDN to spectral radiance; radiance might also be called Top of Atmosphere (TOA) radiance. We can remove the effects of the light source to generate Top of Atmosphere reflectance but usually this is combined within the radiance to reflectance step.\n\nRadiance is when light is on.\nReflectance is when light is off.\nReflectance is a property of a material (e.g. reflectance of grass is a property of grass)\n\nLandsat ARD – Analysis Ready Data – there are algorithms that prepare data but they are not perfect, what are the assumptions, influences. Level 2 product – means something has changed or advanced from level 1.\nJoining data sets/ enhancements in remote sensing it is termed Mosaicking. If our study area is between two tiles, we do join. Before we clip data, we generate a seamline – 10 pixels from both tiles, overlap, and apply histogram matching algorithm."
  },
  {
    "objectID": "week3.html#applications",
    "href": "week3.html#applications",
    "title": "3  Week 3",
    "section": "3.2 Applications",
    "text": "3.2 Applications\nSince geometric distortions are inherit in remote sensing imagery due to the nature of image collection (platform movements) and Earth’s rotation (inevitable), this section focuses on studies that explore various preprocessing methods for geometric correction.\nAs it has been noted by P.Dave, Joshi, and Srivastava (2015) there are a couple of major difficulties occurring during geometric correction such as:\n\nSelection of the feature points form the images\nDetermination of correspondence between images\nSelection of appropriate transformation function\nLack of technique to utilize for images with nonlinear geometric distortion.\n\nSeveral studies have explored a variety of approaches to the aforementioned issues such as Nguyen (2015) who suggested a way to optimize GCP (ground control point) assembly using a genetic/evolution algorithm (GA), compared to traditional GCPs and those selected by a Voronoi diagram approach (Li and Bo 2009). It is concluded that the accuracy of GA-optimized GCPs is hihger than of the other methods.\nMa et al. (2021) provides an overview of available methods intending to overcome second issue (correspondence between images) with area-based matching with machine learning strategies outlines for remote sensing data.\nLin et al. (2024) suggests heterogenous model fitting (MIMF) for multi-source image correspondences as a way to overcome discrepancy between images caused by nonlinear radiation differences and geometric distortions."
  },
  {
    "objectID": "week3.html#reflection",
    "href": "week3.html#reflection",
    "title": "3  Week 3",
    "section": "3.3 Reflection",
    "text": "3.3 Reflection\nThis lecture made me painfully aware how much effort needs to be taken before remote sensing data can be used. I’m glad that there is already numerous amount of appropriate algorithms, and corrected data than can be utilized by researchers. Nevertheless, the wide range of possible image enhancements and adjustments stands as a reminder of imagery limitations, i.e. each correction method entails some shortcomings."
  },
  {
    "objectID": "week4.html#summary",
    "href": "week4.html#summary",
    "title": "4  Week 4",
    "section": "4.1 Summary",
    "text": "4.1 Summary\nImplementation of low emission zone in Poland’s capital, Warsaw, is due to take place from July 2024. It intends to ban an entry for diesel engine cars older than 18 years and gasoline vehicles older than 27 years. This initiative is in line with national spatial policy for Warsaw to raise the rank in the network of European Union cities as one of sustainable economic, social development and protection of natural heritage. Precisely, this is to adhere the policy of The Real Urban Emissions (TRUE) Initiative which is a partnership of the FIA Foundation and the International Council on Clean Transportation with an aim of restricting access to polluting cars and improving urban air quality.\nIn line with the World Bank report, out of 50 most polluted cities in the EU, 36 are located in Poland (World Bank Group 2019). For this reason, initiatives aiming to relieve this matter are of the utmost importance. It has been concluded by Nazar and Niedoszytko (2022) that in Poland, increased values of air pollution are linked with the general increase of respiratory disease mortality rates, higher prevalence of respiratory diseases (e.g. asthma, lung cancer, COVID-19 infections), reduced forced expiratory volume in one second (FEV1) and forced vital capacity (FVC). Therefore, the proximity of high traffic zones has an influence on respiratory health problems. There is an urgent need to reduce air pollution levels.\nWarsaw is among one of the most polluted cities in the European Union and it has one of the highest vehicle ownership rates (859 per 1,000 people) in Europe (STATISTA 2021). Vehicle emissions standards are currently successfully controlled in Warsaw, however they tend to differ during real-world operation quite significantly. For this reason, the use of remote sensors can come as a useful tool allowing policy makers to make informative decisions."
  },
  {
    "objectID": "week4.html#applications",
    "href": "week4.html#applications",
    "title": "4  Week 4",
    "section": "4.2 Applications",
    "text": "4.2 Applications\nRemotely sensed data can provide the insight into the actual vehicles emissions across the streets of Warsaw. Being able to measure the emissions under real driving conditions allow to produce an accurate emissions assessment across urban areas. By combining data from sensors with other, already existing databases, it would be possible to analyse long-term trends and gain a better understanding of emissions of the vehicle fleet. This could lead to a comprehensive analysis, allowing to identify high-emitting vehicle groups, comparing the impact of different ambient conditions, and assessing how emission performance change with the vehicle’s age. Most importantly, this could help to inform the design of aforementioned low emission zones by pointing out which vehicle types would have the most impact on emissions reduction should they be restricted from the zone.\n\n4.2.1 Suggested Methodology\nThe estimation of air pollution can be approached as a supervised computer vision problem as consulted with Scheibenreif, Mommert, and Borth (2021). Datasets can be collected from Sentinel-2, along with measurements from air quality monitoring stations. The proposed model can be trained on pairs of remote sensing input and air quality target values (see Figure 1) to produce a prediction of air pollution level.\n\n\n\nFigure 1. Overview of the proposed air pollution prediction system"
  },
  {
    "objectID": "week4.html#reflection",
    "href": "week4.html#reflection",
    "title": "4  Week 4",
    "section": "4.3 Reflection",
    "text": "4.3 Reflection\nRemote sensing data can support policy of introduction of low emission zone in Warsaw in order to ensure informed decisions regarding zone’s boundaries and to facilitate a gentle introduction of the zone itself. Especially considering the fact that public consultation were met with a big protest from citizens and numerous local councils. For this reason, being able to ensure negative impact of transport on the urban environment is actually reduced, stands as a crucial part of policy introduction."
  },
  {
    "objectID": "week4.html#references",
    "href": "week4.html#references",
    "title": "4  Week 4",
    "section": "4.4 References",
    "text": "4.4 References\n\n\nNazar, Wojciech, and Marek Niedoszytko. 2022. “Air Pollution in Poland: A 2022 Narrative Review with Focus on Respiratory Diseases.” International Journal of Environmental Research and Public Health 19 (2): 895. https://doi.org/10.3390/ijerph19020895.\n\n\nScheibenreif, Linus, Michael Mommert, and Damian Borth. 2021. “Estimation of Air Pollution with Remote Sensing Data: Revealing Greenhouse Gas Emissions from Space.” arXiv. http://arxiv.org/abs/2108.13902.\n\n\nSTATISTA. 2021. “Motorization Rate in Poland 2021.” Statista. https://www.statista.com/statistics/452094/poland-number-of-cars-per-1000-inhabitants/.\n\n\nWorld Bank Group, x. 2019. “Air Quality in Poland, What Are the Issues and What Can Be Done?” September."
  },
  {
    "objectID": "week3.html#references",
    "href": "week3.html#references",
    "title": "3  Week 3",
    "section": "3.4 References",
    "text": "3.4 References\n\n\nLi, Ying, and Cheng Bo. 2009. “Research on Automatic Optimization of Ground Control Points in Image Geometric Rectification Based on Voronoi Diagram,” October. https://doi.org/10.1117/12.813148.\n\n\nLin, Shuyuan, Feiran Huang, Taotao Lai, Jianhuang Lai, Hanzi Wang, and Jian Weng. 2024. “Robust Heterogeneous Model Fitting for Multi-Source Image Correspondences.” International Journal of Computer Vision, February. https://doi.org/10.1007/s11263-024-02023-9.\n\n\nMa, Jiayi, Xingyu Jiang, Aoxiang Fan, Junjun Jiang, and Junchi Yan. 2021. “Image Matching from Handcrafted to Deep Features: A Survey.” International Journal of Computer Vision 129 (1): 23–79. https://doi.org/10.1007/s11263-020-01359-2.\n\n\nNguyen, Thanh. 2015. “Optimal Ground Control Points for Geometric Correction Using Genetic Algorithm with Global Accuracy.” European Journal of Remote Sensing 48 (1): 101–20. https://doi.org/10.5721/EuJRS20154807.\n\n\nP.Dave, Chintan, Rahul Joshi, and S. Srivastava. 2015. “A Survey on Geometric Correction of Satellite Imagery.” International Journal of Computer Applications 116 (April): 24–27. https://doi.org/10.5120/20389-2655."
  },
  {
    "objectID": "week5.html",
    "href": "week5.html",
    "title": "5  Week 5",
    "section": "",
    "text": "No entry required. See you next week!"
  },
  {
    "objectID": "week5.html#summary",
    "href": "week5.html#summary",
    "title": "5  Week 5",
    "section": "5.1 Summary",
    "text": "5.1 Summary"
  },
  {
    "objectID": "week9.html#summary",
    "href": "week9.html#summary",
    "title": "9  Week 9",
    "section": "9.1 Summary",
    "text": "9.1 Summary\nSAR remote sensing satellites are active remote sensing instruments, independent of weather and sun illumination.\n\n9.1.1 How does it work?\nThey transmit electromagnetic microwave from radar antenna and record the backscattered signal from the radar target. Thanks to the use of synthetic antenna which exploits the motion of the aircraft as it comprises multiple images (swath), there is no need for physical antenna, which would have needed to be several kilometers long (!)\n\n\n9.1.2 SAR polarization\nPolarization of SAR implies the orientation of the electrical field of the electromagnetic wave (Figure 1). It affects the nature of what we can see with SAR.\n\n\n\nFigure 1. Horizontally and vertically polarized radar signal\n\n\nShorter wave lengths penetrate less deeply into objects. But for example P-BAND can penetrate way more into, e.g canopy, and therefore it can provide an image for more detailed interpretation, Double Bounce scattering generates very strong return signals.\nRough scattering (e.g. bare earth) = most sensitive to VV (vertical vertical polarization) Volume scattering (e.g. leaves) = cross, VH or HV Double bounce (e.g. trees / buildings) = most sensitive to HH. (horizontal horizontal)\nCertain surfaces absorb electrical systems more strongly -&gt; this property matters for the reflected outcome, e.g. concrete surface vs metal surface. Interestingly, SAR does not penetrate water beyond a few millimeters –&gt; as a consequence one of the limitations of SAR imagery is that moisture (e.g. snow) will make signal to be absorbed differently"
  },
  {
    "objectID": "week9.html#applications",
    "href": "week9.html#applications",
    "title": "9  Week 9",
    "section": "9.2 Applications",
    "text": "9.2 Applications\nChange detection:\n\nExample 1 (from lecture) Phase - location of wave on the cycle when it comes back to the sensor. If the surface changes (due to earthquake for example), by even 3cm (!), the signal will be returned differently. It allows to detect small shifts on the earth surface - it allows to map the changes in elevations\nExample 2 (Ballinger and Zwijnenburg 2023) Pixel Wise T-Test -&gt; the main challange is to identify buildings that have been damaged due to conflicts - when and where. However, in previous projects based on satellite imagery and CNN techniques, there have been following issues observed:\n\nexpensive - it cannot be replicated on the whole country because it needs high resolution imagery to be replicated, e.g. $13.9 million to scan all Ukraine each time\nit is not persistently collected like, e.g. Sentinel 1\nneural networks require training to be accurate in different geographies -&gt; according to Monitoring war destruction from space using machine learning Hannes Mueller -&gt; the issue is train/test split is based on same cities and the accuracy results, if replicated in different cities (even if in the same country) tend to drop significantly. In this case, as explored by Ollie Ballinger, SAR radar imagery can be applied, as it has been presented on the example of Ukraine and Gaza war zones, where flat roof surface (rumbled or not) has been used to detect damaged buildings (possible thanks to changes in backscattering). This method allowed to replicate high accuracies across different cities in different countries. Limitations here: snow on the rooftops!\n\nExample 3 (Dabboor et al. 2018) Wetland Monitoring and Mapping Using Synthetic Aperture Radar Implementation of SAR imagery for water level monitoring, i.e. allows the evaluation of methane emission contributions to climate change from degraded and thawing wetlands. SAR is particularly useful in this case since it provides data regardless of weather conditions and lighting, and wetlands tend to be located in remote areas or under cloud cover.\n\nSAR has become one of the valued remote sensing tools for both soldierly and non-combatant users. Various soldierly SAR applications are intelligence gathering, battlefield survey, and weapons supervision. The non-combatant applications like agricultural and land-use monitoring, topographic planning, geology and mining, oil spill observation, sea ice observation, oceanography and planetary or celestial examinations [11]. SAR has wide practical applications on ocean as well as on land like artificial illegal or coincidental spills are visible in SAR images in the oceans, ships detection and tracking in the oceans, observation of natural leakage from oil deposits in the oceans, providing hints for the oil industries, ocean wave forecasting and marine climatology, regional ice monitoring. This is very crucial and helpful for navigation in ice-infested waters [11].\nSynthetic Aperture Radar. Available at: http://wtlab.iis.u-tokyo.ac.jp/~wataru/lecture/rsgis/rsnote/cp4/cp4-3.htm\nConversely, add some limitations https://link.springer.com/article/10.1007/s11831-021-09548-z"
  },
  {
    "objectID": "week9.html#reflection",
    "href": "week9.html#reflection",
    "title": "9  Week 9",
    "section": "9.3 Reflection",
    "text": "9.3 Reflection\nThis week I am especially amazed by the applications of SAR imagery both in soldierly and non-combatant uses. Its ability to provide a vast data in an affordable way allows for advanced analysis"
  },
  {
    "objectID": "week5.html#reflection",
    "href": "week5.html#reflection",
    "title": "5  Week 5",
    "section": "5.1 Reflection",
    "text": "5.1 Reflection\nNo entry required. See you next week!"
  },
  {
    "objectID": "week6.html",
    "href": "week6.html",
    "title": "6  Week 6",
    "section": "",
    "text": "Google Earth Engine"
  },
  {
    "objectID": "week7.html",
    "href": "week7.html",
    "title": "7  Week 7",
    "section": "",
    "text": "Classification I"
  },
  {
    "objectID": "week8.html",
    "href": "week8.html",
    "title": "8  Week 8",
    "section": "",
    "text": "Classification II"
  },
  {
    "objectID": "week9.html",
    "href": "week9.html",
    "title": "9  Week 9",
    "section": "",
    "text": "Synthetic Aperture Radar (SAR)"
  },
  {
    "objectID": "week9.html#references",
    "href": "week9.html#references",
    "title": "9  Week 9",
    "section": "9.4 References",
    "text": "9.4 References\nLee JS, Pottier E. Polarimetric Radar Imaging: From Basics to Applications. Boca Raton, FL, USA: CRC Press; 2009\n\n\nBallinger, Ollie, and Wim Zwijnenburg. 2023. “Leveraging Emerging Technologies to Enable Environmental Monitoring and Accountability in Conflict Zones  International Review of the Red Cross  Cambridge Core.” https://www.cambridge.org/core/journals/international-review-of-the-red-cross/article/abs/leveraging-emerging-technologies-to-enable-environmental-monitoring-and-accountability-in-conflict-zones/048F61CD42B7C21931B37C091FC2C95F.\n\n\nDabboor, Mohammed, Brian Brisco, Mohammed Dabboor, and Brian Brisco. 2018. “Wetland Monitoring and Mapping Using Synthetic Aperture Radar.” In Wetlands Management - Assessing Risk and Sustainable Solutions. IntechOpen. https://doi.org/10.5772/intechopen.80224."
  },
  {
    "objectID": "week6.html#summary",
    "href": "week6.html#summary",
    "title": "6  Week 6",
    "section": "6.1 Summary",
    "text": "6.1 Summary\n\n6.1.1 What is it?\nGeospatial data processing & analysis cloud-based platform powered by Google; It hosts petabytes of over 40 years of remotely-sensed data, such as Landsat, MODIS, National Oceanographic and Atmospheric Administration Advanced Very High Resolution Radiometer (NOAA AVHRR), Sentinel 1, 2, 3 and 5-P; and Advanced Land Observing Satellite (ALOS) data (Gorelick et al. 2017). MODIS collections for example, provide a twice a day global coverage.\nGEE platform data is publicly available and is designed to be used with an explorer web app. It also provides various machine learning algorithms based on Google’s computational infrastructure and allows for high-speed parallel processing. In addition it provides library of APIs enabling the use of JavaScript and Python for analysis (Tamiminia et al. 2020).\nThis tool enables for analysis and visualizing big geospatial data without access to supercomputer or specialized coding expertise (cool!)"
  },
  {
    "objectID": "week6.html#applications",
    "href": "week6.html#applications",
    "title": "6  Week 6",
    "section": "6.2 Applications",
    "text": "6.2 Applications\nOverall, the Google Earth Engine has a vast and growing presence across the current literature. It has found its applications in the analysis of many societal issues such as: deforestation, drought, disaster, disease, food security, water management, climate monitoring, and environmental protection, as pointed by Gorelick et al. (2017).\nSince GEE is a rather multidisciplinary tool with many applications, I will focus on one particular research that I found quite interesting, i.e. application for wetland mapping and monitoring using sentinel data. Fekri et al. (2021) presents its methodology (Figure 1) using a combination of Sentinel-1 and Sentinel-2 images and the pixel-based Random Forest (RF) classifier within GEE. Wetland maps were generated with a 10-m spatial resolution which yielded Overall Accuracy and Kappa coefficient values of respectively, 97.98% and 0.97, which indicates the high efficiency of the proposed method in mapping of this ecosystem. It has been pointed that despite GEE offering a preprocessed data, the Sentinel-1 scenes included speckle noise, which has a negative impact on the classification results as it has been concluded by other studies (Adeli et al. 2020). This signals as a reminder for further research to ensure pre-processing steps in their methodologies. This study proved to result in a time-saving and cost-efficient method of intensive field data collection, allowing to map and monitor important environmental changes.\n\n\n\nFigure 1. Methodology used in Wetland Monitoring Using SAR Data: A Meta-Analysis and Comprehensive Review (2020)\n\n\nConsidering the numerous advantages of Google Earth Engine, it is easy to forget about its negative externalities! As it has been noted by Wilkinson et al. (2024), “A simple band arithmetic function applied to a Landsat 9 scene using Google Earth Engine (GEE) generated CO2 equivalent (e) emissions of 0.042–0.69 g CO2e (locally) and 0.13–0.45 g CO2e”. There have been many studies signaling that data centres are already producing CO2 emissions similar in a scale to emissions from aviation (Lucivero 2020). I think this information should be treated as a motivation to seek more transparency from cloud services regarding their data life-cycle impacts, and the actual cost of cloud computation."
  },
  {
    "objectID": "week6.html#references",
    "href": "week6.html#references",
    "title": "6  Week 6",
    "section": "6.4 References",
    "text": "6.4 References\n\n\nAdeli, Sarina, Bahram Salehi, Masoud Mahdianpari, Lindi J. Quackenbush, Brian Brisco, Haifa Tamiminia, and Stephen Shaw. 2020. “Wetland Monitoring Using SAR Data: A Meta-Analysis and Comprehensive Review.” Remote Sensing 12 (14): 2190. https://doi.org/10.3390/rs12142190.\n\n\nFekri, Erfan, Hooman Latifi, Meisam Amani, and Abdolkarim Zobeidinezhad. 2021. “A Training Sample Migration Method for Wetland Mapping and Monitoring Using Sentinel Data in Google Earth Engine.” Remote Sensing 13 (20): 4169. https://doi.org/10.3390/rs13204169.\n\n\nGorelick, Noel, Matt Hancher, Mike Dixon, Simon Ilyushchenko, David Thau, and Rebecca Moore. 2017. “Google Earth Engine: Planetary-Scale Geospatial Analysis for Everyone.” Remote Sensing of Environment, Big Remotely Sensed Data: Tools, applications and experiences, 202 (December): 18–27. https://doi.org/10.1016/j.rse.2017.06.031.\n\n\nLucivero, Federica. 2020. “Big Data, Big Waste? A Reflection on the Environmental Sustainability of Big Data Initiatives.” Science and Engineering Ethics 26 (2): 1009–30. https://doi.org/10.1007/s11948-019-00171-7.\n\n\nTamiminia, Haifa, Bahram Salehi, Masoud Mahdianpari, Lindi Quackenbush, Sarina Adeli, and Brian Brisco. 2020. “Google Earth Engine for Geo-Big Data Applications: A Meta-Analysis and Systematic Review.” ISPRS Journal of Photogrammetry and Remote Sensing 164 (June): 152–70. https://doi.org/10.1016/j.isprsjprs.2020.04.001.\n\n\nWilkinson, R., M. M. Mleczko, R. J. W. Brewin, K. J. Gaston, M. Mueller, J. D. Shutler, X. Yan, and K. Anderson. 2024. “Environmental Impacts of Earth Observation Data in the Constellation and Cloud Computing Era.” Science of The Total Environment 909 (January): 168584. https://doi.org/10.1016/j.scitotenv.2023.168584."
  },
  {
    "objectID": "week6.html#reflections",
    "href": "week6.html#reflections",
    "title": "6  Week 6",
    "section": "6.3 Reflections",
    "text": "6.3 Reflections\nThis week I guess I embedded some of the reflective notion within the part above as well. Nevertheless, it is extremely interesting to see the exponential increase in number of articles published regarding GEE. Availability of this data, even though it still requires expertise to use, has opened many opportunities for researches from around the world, and even hobbyists. This is a great step towards democratization of data access and distribution of power. Nevertheless, with great power comes great responsibility! As I mentioned earlier, all of the consequences need to be taken into account, e.g. carbon footprint (!), insufficient data centres’ environmental policies, etc. At the end of the day, there is no such thing as a free lunch."
  },
  {
    "objectID": "week7.html#summary",
    "href": "week7.html#summary",
    "title": "7  Week 7",
    "section": "7.1 Summary",
    "text": "7.1 Summary\nClassification refers to the process of categorizing pixels in satellite imagery into distinct classes or categories based on their spectral signatures, textural features, or other characteristics detectable from the imagery. This is in line with Tobler’s first law of geography, i.e. closer things are more related.\n\n7.1.1 How does it work?\nExpert Systems - a system that uses human knowledge to solve problems that require human intelligence, e.g. training datasets.\nMachine Learning\nIs linear regression machine learning? Yes, it can be considered so. Types of ML:\n- classification trees - classify data into two or more discrete categories, e.g. should I play golf today? - regression trees - predict continuous dependent variable, e.g. GCSE score\nOverfitting - too perfect model, 100% accuracy, most likely useless, e.g leaf with just one person or pixel value\nUnderfitting - potentially can happen when forcing a linear relationship in regression when out data in not linear.\n- random forests - produce bootstrap samples; many decision trees with less control (from a random numver of variables)\n- image classification: - unsupervised (pixels are grouped into “clusters” based on their properties, and each “cluster” is classified with a land cover class)\n\nSupervised (representative samples are chosen for each land cover class, and based on the training set results, this is replicated for the entire image)\nOBIA - object based image analysis (especially useful for high-resolution data because it uses both spectral and contextual information; pixels are grouped into representative vector shapes with size and geometry)\n\nInterestingly, higher resolution images do not guarantee better land cover. The image classification techniques used are a very important factor for better accuracy."
  },
  {
    "objectID": "week7.html#applications",
    "href": "week7.html#applications",
    "title": "7  Week 7",
    "section": "7.2 Applications",
    "text": "7.2 Applications\nThe goal of classification in environmental and Earth sciences is often to monitor changes over time, assess ecosystem health, plan conservation efforts, or understand human impact on natural landscapes, among other applications. In recent years, the use of deep learning in remote sensing image classification is becoming more and more popular, especially thanks to its powerful feature extraction capabilities and robustness (Dou et al. 2021).\nBrazil case from lecture: Monitoring forests + illegal logging - instead of using the raw Earth observation data, they’re making composites, they’re taking part of the data that are most relevant for their application, so here we have maximum, minimum, mean values and some kind of linear regression also happening. And then from those metrics they are then using a classifier on the metrics as opposed to the raw Google data. Forest fires paper - vegetation was from a classified Landsat TM image - classified 16 categories.\nFeng et al. (2023) study aims to develop a deep learning framework to improve the accuracy of crop type identification using Sentinel 2 data. Researchers built a time-series image classification framework using Attention-based Bidirectional Gated Recurrent Unit (A-BiGRU) to map rice, maize, and soybean in Fujin region of China, from reconstructed Sentinel-2 time-series images. Figure 1 demonstrates methodolgy used in this study. Interestingly, despite its the inherent disadvantage of CNNs is the need for a large number of spatially labeled samples as it has been observed by Gallo et al. (2023). Nevertheless, different studies which focused on using a different algorithm, e.g. Wei et al. (2023) who used RF algorithm also on Sentinel 2 data, was able to achieve a significantly higher accuracy. Their study was based on random forest importance and normalization, which concluded in a strong performance for early crop mapping.\n\n\n\nFigure 1. Methodology used in A deep learning framework for crop mapping with reconstructed Sentinel-2 time series images (2021)"
  },
  {
    "objectID": "week7.html#reflections",
    "href": "week7.html#reflections",
    "title": "7  Week 7",
    "section": "7.3 Reflections",
    "text": "7.3 Reflections\nCase of Brazil forest monitoring was among the most thought provoking this week for me. Fact that the area of a forest the size of Nepal can be monitored by two employees with two vehicles, a boat and a drone and provide a sufficient image within 20 minutes is just incredible, how efficient this is! At the same time, it is also a bit scary to think about its monitoring capabilities… is there a line between control, justice and big brother entering into our lives? Nevertheless, it is incredible how all of the image classification efforts (as in example from China) may result in tools able to predict crop yield and monitor its growth, indirectly ensuring food security. I found it interesting to find out about machine learning real use-cases. I’m quite amazed with its vast options and and seemingly endless opportunities for accuracy improvements."
  },
  {
    "objectID": "week8.html#summary",
    "href": "week8.html#summary",
    "title": "8  Week 8",
    "section": "8.1 Summary",
    "text": "8.1 Summary\nThis entry is a continuation of classification topic.\nThere are available sources of pre-classified data that can be used instead of producing own datasets: - GlobeLand30 - European Space Agency’s (ESA) Climate Change Initiative (CCI) - Dynamic World - near real time 10m - MODIS - Google building data\nDynamic World datasets are using semi-supervised approach - stratification based; trained with the expert group. Mapping unit is 5x5 pixels, therefore its limitation is that it can include various land uses. It is based on CNNs with accuracy assess through Confusion matrix. Training data available at Radiant MLHub.\nObject based image analysis (OBIA) - they are based on SLIC (Simple Lienar Iterative Clustering) Algorithm for Superpixel generation. It measure the distance from point to the centre of the pixel\nSub pixel analysis (aka Spectral Mixture Analysis) - identification of the composition of land cover types per single pixel; with the use of comparing our findings to the known spectrally pure endmembers; V-I-S triangle is used here\nAccuracy assessment - this process involves comparing the classified data against the actual data in order to determine how well it performs. Common metrics used in accuracy assessment include overall accuracy (OA), producer’s accuracy, user’s accuracy, errors of omission, errors of commission and the Kappa coefficient.\nSpatial cross validation - cross-validation techniques based on random split of the dataset into training and testing subsets. Crucial for models applied to geographic data because nearby observations are often more similar to each other than to distant observations, due to spatial autocorrelation."
  },
  {
    "objectID": "week8.html#applications",
    "href": "week8.html#applications",
    "title": "8  Week 8",
    "section": "8.2 Applications",
    "text": "8.2 Applications\nImage classification has various innovative applications, with one of them that amazes me the most is possibility to detect floating plastics in water bodies (Basu et al. 2021).This and many other capabilities behind image classification allows to respond to a range of environmental issues in a very efficient way. Very impressing! I did delve down into a more methodological applications after that:\nIn the study by Saba et al. (2023), three classification methods were evaluated for the purpose of detecting co-seismic landslides in seismically active area in Lesser Himalaya in Pakistan. Maximum Likelihood Classification, OBIA, and COSI-Corr were analyzed for the purpose of identifying their accuracy levels and model reliability (Figure 1). It has been concluded that MLC classification technique is performing worse than other pixel-based landslide classification algorithms which is consistent with other existing literature (Saba et al. 2019). COSI-Corr offered better outcome thanks to the sub-pixel analysis and employing extra masks for landslide detection. This has also been confirmed by Saba et al. (2017). However, as a consequence of natural variation and atmospheric effects, this method resulted in some extent of spleckled noise in pixels, which in consequence leads to spectral image being exhibited differently. Similar study by Montagnon et al. (2022) also explored this method for ground deformation study disregarding use of COSI-Corr for CNN-DATe which provided them with results of better accuracy. Back to the initial paper, third method OBIA’s performance was deemed as highly dependent on the spatial resolution of the imagery.\n\n\n\nFigure 1. Comparison of classification techniques (yellow), i.e. a Pixel-based MLC, b Object–based and c COSI-Corr"
  },
  {
    "objectID": "week8.html#reflections",
    "href": "week8.html#reflections",
    "title": "8  Week 8",
    "section": "8.3 Reflections",
    "text": "8.3 Reflections\nTo Kappa or not to Kappa? I have to admit, this material was rather challenging for me in comprehension since it introduced a lot of new vocabulary and acronyms into my life. Nevertheless, I find them very helpful, and now when I read articles, I am able to understand more dimensions of methodological descriptions than before. In addition, it seems that radiant MLHub might come very handy for my other machine learning projects I’m doing!"
  },
  {
    "objectID": "week9.html#song-of-the-week",
    "href": "week9.html#song-of-the-week",
    "title": "9  Week 9",
    "section": "9.4 Song of the week",
    "text": "9.4 Song of the week\nParanoid London"
  },
  {
    "objectID": "week8.html#references",
    "href": "week8.html#references",
    "title": "8  Week 8",
    "section": "8.4 References",
    "text": "8.4 References\n\n\nBasu, Bidroha, Srikanta Sannigrahi, Arunima Sarkar Basu, and Francesco Pilla. 2021. “Development of Novel Classification Algorithms for Detection of Floating Plastic Debris in Coastal Waterbodies Using Multispectral Sentinel-2 Remote Sensing Imagery.” Remote Sensing 13 (8): 1598. https://doi.org/10.3390/rs13081598.\n\n\nMontagnon, Tristan, James Hollingsworth, Erwan Pathier, Mathilde Marchandon, Mauro Dalla Mura, and Sophie Giffard-Roisin. 2022. “Sub-Pixel Optical Satellite Image Registration for Ground Deformation Using Deep Learning.” In 2022 IEEE International Conference on Image Processing (ICIP), 2716–20. https://doi.org/10.1109/ICIP46576.2022.9897214.\n\n\nSaba, Sumbal Bahar, Muhammad Ali, Mark van der Meijde, and Harald van der Werff. 2017. “Co-Seismic Landslides Automatic Detection on Regional Scale with Sub-Pixel Analysis of Multi Temporal High Resolution Optical Images: Application to Southwest of Port Au Prince, Haiti.” Journal of Himalayan Earth Sciences 50 (2): 74–92.\n\n\nSaba, Sumbal Bahar, Muhammad Ali, Syed Ali Turab, Muhammad Waseem, and Shah Faisal. 2023. “Comparison of Pixel, Sub-Pixel and Object-Based Image Analysis Techniques for Co-Seismic Landslides Detection in Seismically Active Area in Lesser Himalaya, Pakistan.” Natural Hazards 115 (3): 2383–98. https://doi.org/10.1007/s11069-022-05642-y.\n\n\nSaba, Sumbal Bahar, Nimat Ullah Khattak, Muhammad Ali, Muhammad Waseem, Samina Siddiqui, Seema Anjum, and Syed Ali Turab. 2019. “Application of Sub-Pixel-Based Technique ‘Orthorectification of Optically Sensed Images and Its Correlation’ for Co-Seismic Landslide Detection and Its Accuracy Modification Through the Integration of Various Masks.” Journal of Himalayan Earth Sciences 52 (1): 37–50."
  },
  {
    "objectID": "week7.html#references",
    "href": "week7.html#references",
    "title": "7  Week 7",
    "section": "7.4 References",
    "text": "7.4 References\n\n\nDou, Peng, Huanfeng Shen, Zhiwei Li, Xiaobin Guan, and Wenli Huang. 2021. “Remote Sensing Image Classification Using Deep–Shallow Learning.” IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing 14 (January): 3070–83. https://doi.org/10.1109/JSTARS.2021.3062635.\n\n\nFeng, Fukang, Maofang Gao, Ronghua Liu, Shuihong Yao, and Guijun Yang. 2023. “A Deep Learning Framework for Crop Mapping with Reconstructed Sentinel-2 Time Series Images.” Computers and Electronics in Agriculture 213 (October): 108227. https://doi.org/10.1016/j.compag.2023.108227.\n\n\nWei, Peng, Huichun Ye, Shuting Qiao, Ronghao Liu, Chaojia Nie, Bingrui Zhang, Lijuan Song, and Shanyu Huang. 2023. “Early Crop Mapping Based on Sentinel-2 Time-Series Data and the Random Forest Algorithm.” Remote Sensing 15 (13): 3212. https://doi.org/10.3390/rs15133212."
  },
  {
    "objectID": "week3.html#reflections",
    "href": "week3.html#reflections",
    "title": "3  Week 3",
    "section": "3.3 Reflections",
    "text": "3.3 Reflections"
  }
]