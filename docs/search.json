[
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "Remote sensors. Test\nXYSZ\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "CASA0023 Remote Sensing - Learning Diary",
    "section": "",
    "text": "Introduction\nHello!\nMy name is Marta, I am currently pursuing a master degree of Social and Geographic Data Science. My hallmark is the global outlook which I developed while studying and working in Chile, Spain, Poland and the UK. Coming from management, economics and finance background, I am happy to return to academia, aiming to leverage my practical experience in making a wider societal impact.\n\n\n\nSource: https://www.instagram.com/p/C3GfvH1OiFk/"
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "3  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "week2.html",
    "href": "week2.html",
    "title": "2  Week 2",
    "section": "",
    "text": "Xaringan Presentation\nThis week content is a presentation in Xaringan on the selected sensor. Summary, application and reflection are all included in the presentation below:"
  },
  {
    "objectID": "week1.html",
    "href": "week1.html",
    "title": "1  Week 1",
    "section": "",
    "text": "Getting started with remote sensing"
  },
  {
    "objectID": "week4.html",
    "href": "week4.html",
    "title": "4  Week 4",
    "section": "",
    "text": "Policy"
  },
  {
    "objectID": "week3.html",
    "href": "week3.html",
    "title": "3  Week 3",
    "section": "",
    "text": "Corrections"
  },
  {
    "objectID": "week1.html#summary",
    "href": "week1.html#summary",
    "title": "1  Week 1",
    "section": "1.1 Summary",
    "text": "1.1 Summary\n\n1.1.1 What is remote sensing?\nRemote sensing can be concluded as acquiring information from a distance which can be obtained via sensors. Remote sensors are devices that make use of the electromagnetic spectrum (Figure 1) and atmospheric transmission windows in order to observe a chosen target. Most remote sensors measure either an intensity change or a phase change of EM radiation.\n\n\n\nFigure 1. Simplified representation of the electromagnetic spectrum\n\n\nSensors can be divided into active and passive. Passive sensors detect natural energy emitted or reflected by the Earth, for example, optical sensors which are able to capture sunlight reflection (Figure 2a), while active sensors emit energy and measure the reflected or backscattered signals (Figure 2b). This wide range of sensors enables remote sensing data to be acquired via satellites for global coverage, aircraft for higher spatial resolution, and even drones for small-scale data collection.\n\n\n\nFigure 2. (a) Passive remote sensing: the sensor receives information. (b) Active remote sensing: the sensor emits and receives information.\n\n\n\n\n1.1.2 Scattering\nAtmospheric scattering occurs when the particles or gaseous molecules present in the atmosphere cause the EM radiation to be redirected from its original path. The amount of scattering depends on several factors including the wavelength of the radiation, the amount of particles and gases, and the distance the radiant energy travels through the atmosphere. Three types of scattering:\n-Rayleigh scattering – electromagnetic radiation interacts with particles that are smaller than the wavelengths of light -&gt; it disturbs RS in the visible spectral range from high altitudes. Due to Rayleigh scattering the shorter wavelengths are overestimated. It diminishes the ‘crispness’ of photos -&gt; has a negative effect on digital classification using data from multispectral sensors.\n-Mie scattering – occurs when the wavelength of the EM radiation is similar in size to the atmospheric particles (e.g. aerosols, a mixture of gases, water vapour, dust). Influences the spectral range from near-UV up to mid-IR, and has a greater effect on radiation of longer wavelengths than Rayleigh scattering\n-Non-selective scattering – occurs when the particle size is much larger than the radiation wavelength. For example, water droplets and larger dust particles. The most characteristic example is that we see clouds as white bodies. Important: clouds pose a great limitation – remote sensors cannot see through them, and they cast shadows.\nSince electromagnetic energy is partly absorbed by various molecules in the atmosphere, such as ozone, water vapour, and carbon dioxide, it may be concluded that many of the wavelengths are not useful for remote sensing of Earth’s surface, due to the corresponding energy not being able to penetrate the atmosphere. According to (Tempfli et al. 2009) only the spectrum portions can be used for remote sensing, they are referred to as atmospheric transmission windows."
  },
  {
    "objectID": "week1.html#applications",
    "href": "week1.html#applications",
    "title": "1  Week 1",
    "section": "1.2 Applications",
    "text": "1.2 Applications\nDue to solar energy being reflected differently based on surface characteristics, remote sensors are able to collect information which can reflect characteristics of vegetation since its properties can be detected dues to differences in energy reflection. The amount of energy reflected for a particular wavelength depends on leaf pigmentation, leaf thickness and composition (cell structure), and on the amount of water in the leaf tissue. Optical remote sensing can provide information about the type of plant and about its health condition. Or even forest biodervisity can be tracked with the use of remote sensors which are able to provide detailed information on key leaf traits such as leaf mass per area (wow!) (Gara, Rahimzadeh-Bajgiran, and Darvishzadeh 2021). Similarly, this can be applied for different types of soil too. For example, iron dominated soil has a significantly different reflectance curve, due to the iron absorption. This ‘feature’ of remote sensing can allow for detecion of soil contamination as Chen et al. (2024) did who in order to detect Chromium pollution used variability of soil spectra. Additionally, different forms of radiant energy allows to determine information regarding terrain surface (Poppiel et al. 2020) . Wójtowicz, Wójtowicz, and Piekarczyk (2016) presented how to optimize profitability of agricultural crop production with the use of remote sensors. This capability can be especially beneficial for farmers allowing them to make informed decisions optimizing agricultural practices. However, as it has been pointed by Jensen et al. (2009), remote sensing data analysis might be costly, and require some expert knowledge. For this reason, not all farmers, as in the outlined case, would be able to benefit from this opportunity. Perhaps, only the biggest farming corporations are able to benefit of such practices."
  },
  {
    "objectID": "week1.html#reflection",
    "href": "week1.html#reflection",
    "title": "1  Week 1",
    "section": "1.3 Reflection",
    "text": "1.3 Reflection\nThe most interesting and life-changing part of this lecture was finally getting an answer to the biggest question of my life, why the sky is blue during a day, and orange/red during a sunset. Answer lies in scattering of sunlight. Due to difference in wave sizes, blue light is visible since it travels as shorter and smaller waves. This changes when the Sun gets lower in the sky, its light passes through more of the atmosphere, allowing the reds and yellows to pass straight through to our eyes.\nAnother interesting realization is the amount of objects located in the atmosphere. This raises questions whether there are sufficient policies in place that would regulate the amount of cluster, control its life cycle and ensuring suitable recycling or removal."
  },
  {
    "objectID": "week1.html#references",
    "href": "week1.html#references",
    "title": "1  Week 1",
    "section": "1.4 References",
    "text": "1.4 References\n\n\nChen, Lihan, Kun Tan, Xue Wang, and Yu Chen. 2024. “A Rapid Soil\nChromium Pollution Detection Method Based on Hyperspectral\nRemote Sensing Data.” International Journal of Applied Earth\nObservation and Geoinformation 128 (April): 103759. https://doi.org/10.1016/j.jag.2024.103759.\n\n\nGara, Tawanda W., Parinaz Rahimzadeh-Bajgiran, and Roshanak\nDarvishzadeh. 2021. “Forest Leaf Mass\nPer Area (LMA) Through the Eye of\nOptical Remote Sensing:\nA Review and Future\nOutlook.” Remote Sensing 13 (17): 3352. https://doi.org/10.3390/rs13173352.\n\n\nJensen, Ryan R., Perry J. Hardin, Matthew Bekker, Derek S. Farnes, Vijay\nLulla, and Andrew Hardin. 2009. “Modeling Urban Leaf Area Index\nwith AISA+ Hyperspectral Data.” Applied\nGeography 29 (3): 320–32. https://doi.org/10.1016/j.apgeog.2008.10.001.\n\n\nPoppiel, Raúl Roberto, Marilusa Pinto Coelho Lacerda, Rodnei Rizzo, José\nLucas Safanelli, Benito Roberto Bonfatti, Nélida Elizabet Quiñonez\nSilvero, and José Alexandre Melo Demattê. 2020. “Soil\nColor and Mineralogy Mapping\nUsing Proximal and Remote\nSensing in Midwest\nBrazil.” Remote Sensing 12 (7): 1197. https://doi.org/10.3390/rs12071197.\n\n\nTempfli, Klaus, G. C. Huurneman, Wim Bakker, L. L. F. Janssen, W. F.\nFeringa, Ambro Gieske, K. A. Grabmaier, et al. 2009. “Principles\nof Remote Sensing : An Introductory Textbook.” In, 56–85.\n\n\nWójtowicz, Marek, Andrzej Wójtowicz, and J. Piekarczyk. 2016.\n“Application of Remote Sensing Methods in Agriculture” 11\n(January): 31–50."
  },
  {
    "objectID": "week3.html#summary",
    "href": "week3.html#summary",
    "title": "3  Week 3",
    "section": "3.1 Summary",
    "text": "3.1 Summary\n\nGeometric correction – distortion due to wind, Earth rotation, etc. Points are identified in a satellite image, and true image, e.g. Open Street Map (true representation of Earth). Ground control point is this location in image X, and find it on image Y. Then linear regression with distorted image and with gold standard data is performed. From Gold to EO. The more control points, the lower the error will be.\nAtmospheric correction – distortion due to haze or scattering; adjacency effect – pixels bleeding into other pixels; two ways to remove effects of atmosphere:\no relative - Dark object subtraction (DOS) or histogram adjustment; Psuedo-invariant Features (PIFs). o absolute (definitive) – done through atmospheric radiative transfer models or empirical line correction – using a field spectrometer, and the you do linear regression between these values. Path radiance (radiance reflected above the surface), atmospheric attenuation (absorption of EMR due to materials in atmosphere)\nOrthorectification correction – subset of georectification;\ngeorectification = giving coordinates to an image;\northorectification = removing distortions… making the pixels viewed at nadir (straight down) Atmospheric correction has to be done before topographic correction Radiometric Calibration - sensors capture image brightness and distributed as a Digital Number (or DN) - allows for efficient storage but has no units! Sensor calibration = linear regression;\nDN to spectral radiance; radiance might also be called Top of Atmosphere (TOA) radiance. We can remove the effects of the light source to generate Top of Atmosphere reflectance but usually this is combined within the radiance to reflectance step.\nRadiance is when light is on.\nReflectance is when light is off.\nReflectance is a property of a material (e.g. reflectance of grass is a property of grass)\n\nLandsat ARD – Analysis Ready Data – there are algorithms that prepare data but they are not perfect, what are the assumptions, influences. Level 2 product – means something has changed or advanced from level 1.\nJoining data sets/ enhancements in remote sensing it is termed Mosaicking. If our study area is between two tiles, we do join. Before we clip data, we generate a seamline – 10 pixels from both tiles, overlap, and apply histogram matching algorithm."
  },
  {
    "objectID": "week3.html#applications",
    "href": "week3.html#applications",
    "title": "3  Week 3",
    "section": "3.2 Applications",
    "text": "3.2 Applications\nSince geometric distortions are inherit in remote sensing imagery, this section focuses on studies that explore various preprocessing methods for geometric correction. As it has been noted by [REFERECNE], there are https://www.researchgate.net/profile/Rahul-Joshi-18/publication/276128802_A_Survey_on_Geometric_Correction_of_Satellite_Imagery/links/5c6a8a97299bf1e3a5af6807/A-Survey-on-Geometric-Correction-of-Satellite-Imagery.pdf Following are the major difficulties occurred during geometric correction process. 1. Selection of the feature points from the images 2. Determination of correspondence between images 3. Selection of right transformation function that can represents geometric distortion between images 4. No technique to determine correspondence between features points when the images have nonlinear geometric distortions. ## Reflection This lecture made me painfully aware how much effort needs to be taken before remote sensing data can be used. I’m glad that there is already numerous amount of appropriate algorithms, and corrected data than can be utilized by researchers. Nevertheless, the wide range of possible image enhancements and adjustments stands as a reminder of imagery limitations, i.e. each correction method entails some shortcomings."
  },
  {
    "objectID": "week3.html#reflection",
    "href": "week3.html#reflection",
    "title": "3  Week 3",
    "section": "3.3 Reflection",
    "text": "3.3 Reflection"
  },
  {
    "objectID": "week4.html#summary",
    "href": "week4.html#summary",
    "title": "4  Week 4",
    "section": "4.1 Summary",
    "text": "4.1 Summary\nImplementation of low emission zone in Poland’s capital, Warsaw, is due to take place from July 2024. This is in line with national spatial policy for Warsaw to raise the rank in the network of European Union cities as one of sustainable economic, social development and protection of natural heritage.  Precisely, this is to adhere the policy of The Real Urban Emissions (TRUE) Initiative which is a partnership of the FIA Foundation and the International Council on Clean Transportation with an aim of restricting access to polluting cars and improving urban air quality.\nAccording to the World Bank Group, 36 of the 50 most polluted cities in the European Union are in Poland. Thus, ambient air pollution and its detrimental health effects are a matter of immense importance in Poland. This narrative review aims to analyse current findings on air pollution and health in Poland, with a focus on respiratory diseases, including COVID-19, as well as the Poles’ awareness of air pollution. PubMed, Scopus and Google Scholar databases were searched. In total, results from 71 research papers were summarized qualitatively. In Poland, increased air pollution levels are linked to increased general and respiratory disease mortality rates, higher prevalence of respiratory diseases, including asthma, lung cancer and COVID-19 infections, reduced forced expiratory volume in one second (FEV1) and forced vital capacity (FVC). The proximity of high traffic areas exacerbates respiratory health problems. People living in more polluted regions (south of Poland) and in the winter season have a higher level of air pollution awareness. There is an urgent need to reduce air pollution levels and increase public awareness of this threat. A larger number of multi-city studies are needed in Poland to consistently track the burden of diseases attributable to air pollution.\nSince the air pollution is among the major environmental health risks globally, causing almost 4.5 million premature deaths in 2019 (reference), the transportation sector, which is the leading source of this problem, should be addressed with additional consideration. Vehicle emissions standards are currently successfully controlled, however they tend to differ during real-world operation quite significantly. For this reason, the use of remote sensors can come as a useful tool allowing policy makers to make informative decisions."
  },
  {
    "objectID": "week4.html#applications",
    "href": "week4.html#applications",
    "title": "4  Week 4",
    "section": "4.2 Applications",
    "text": "4.2 Applications\nRemotely sensed data can provide the insight into the actual vehicles emissions across the streets of Warsaw. Being able to measure the emissions under real driving conditions allow to produce an accurate emissions assessment across urban areas. By combining data from sensors with other, already existing databases, it would be possible to analyse long-term trends and gain a better understanding of emissions of the vehicle fleet. This could lead to a comprehensive analysis, allowing to identify high-emitting vehicle groups, comparing the impact of different ambient conditions, and assessing how emission performance change with the vehicle’s age. Most importantly, this could help to inform the design of aforementioned low emission zones by pointing out which vehicle types would have the most impact on emissions reduction should they be restricted from the zone.\n\n4.2.1 Suggested Methodology\nThe estimation of air pollution can be approached as a supervised computer vision problem. Datasets can be collected from Sentinel-2 and Sentinel-5P, spatially and temporally aligned with measurements from air quality monitoring stations. The proposed model can be trained on pairs of remote sensing input and air quality target values (see Figure 1), which yields a system that predicts air pollution levels solely from globally available remote sensing data.\n\n\n\nFigure 1. Overview of the proposed air pollution prediction system\n\n\nNO2 measurements by EEA air quality stations would have to be filtered to remove values with insufficient quality. To investigate the possibility to estimate NO2 concentrations at quarterly and monthly frequencies, the mean of NO2 measurements for each frequency could be used as prediction target. To build the dataset, Sentinel-2 Level-2A data could be downloaded(i.e. corrected for atmospheric effects and enriched with cloud masks) with low cloud-coverage at the locations of air quality stations, containing 12 different bands (band 10 is empty in the case of Level-2A data). The images could then be cropped to 120×120 pixel size (∼1.2×1.2 km) centered at the location of interest. Additionally, this would be followed by visual inspection of the RGB bands of all images to ensure that no clouds or artifacts are present."
  },
  {
    "objectID": "week4.html#reflection",
    "href": "week4.html#reflection",
    "title": "4  Week 4",
    "section": "4.3 Reflection",
    "text": "4.3 Reflection\n\nThe reflection criterion will refer to what you have learnt in relation to the policy, city and the application of the data. Fun fact, they stopped this projects with protests, etc. …"
  },
  {
    "objectID": "week4.html#references",
    "href": "week4.html#references",
    "title": "4  Week 4",
    "section": "4.4 References",
    "text": "4.4 References"
  },
  {
    "objectID": "week3.html#references",
    "href": "week3.html#references",
    "title": "3  Week 3",
    "section": "3.3 References",
    "text": "3.3 References"
  },
  {
    "objectID": "week5.html",
    "href": "week5.html",
    "title": "5  Week 5",
    "section": "",
    "text": "No entry required. See you next week!"
  },
  {
    "objectID": "week5.html#summary",
    "href": "week5.html#summary",
    "title": "5  Week 5",
    "section": "5.1 Summary",
    "text": "5.1 Summary"
  },
  {
    "objectID": "week9.html#summary",
    "href": "week9.html#summary",
    "title": "9  Week 9",
    "section": "9.1 Summary",
    "text": "9.1 Summary\nSAR remote sensing satellites are active remote sensing instruments, independent of weather and sun illumination.\n\n9.1.1 How does it work?\nThey transmit electromagnetic microwave from radar antenna and record the backscattered signal from the radar target (Lee, 2009). Thanks to the use of synthetic antenna which exploits the motion of the aircraft as it comprises multiple images (swath), there is no need for physical antenna, which would have needed to be several kilometers long (!)\n\n\n9.1.2 SAR polarization\nPolarization of SAR implies the orientation of the electrical field of the electromagnetic wave (Figure 1). It affects the nature of what we can see with SAR.\n\n\n\nFigure 1. Horizontally and vertically polarized radar signal\n\n\nShorter wave lengths penetrate less deeply into objects. But for example P-BAND can penetrate way more into, e.g canopy, and therefore it can provide an image for more detailed interpretation, Double Bounce scattering generates very strong return signals.\nRough scattering (e.g. bare earth) = most sensitive to VV (vertical vertical polarization) Volume scattering (e.g. leaves) = cross, VH or HV Double bounce (e.g. trees / buildings) = most sensitive to HH. (horizontal horizontal)\nCertain surfaces absorb electrical systems more strongly -&gt; this property matters for the reflected outcome, e.g. concrete surface vs metal surface. Interestingly, SAR does not penetrate water beyond a few millimeters –&gt; as a consequence one of the limitations of SAR imagery is that moisture (e.g. snow) will make signal to be absorbed differently"
  },
  {
    "objectID": "week9.html#applications",
    "href": "week9.html#applications",
    "title": "9  Week 9",
    "section": "9.2 Applications",
    "text": "9.2 Applications\nChange detection:\n\nExample 1 (from lecture) Phase - location of wave on the cycle when it comes back to the sensor. If the surface changes (due to earthquake for example), by even 3cm (!), the signal will be returned differently. It allows to detect small shifts on the earth surface - it allows to map the changes in elevations\nExample 2 (reference: https://www.economist.com/interactive/briefing/2023/02/23/data-from-satellites-reveal-the-vast-extent-of-fighting-in-ukraine) Pixel Wise T-Test -&gt; the main challange is to identify buildings that have been damaged due to conflicts - when and where. However, in previous projects based on satellite imagery and CNN techniques, there have been following issues observed:\n\nexpensive - it cannot be replicated on the whole country because it needs high resolution imagery to be replicated, e.g. $13.9 million to scan all Ukraine each time\nit is not persistently collected like, e.g. Sentinel 1\nneural networks require training to be accurate in different geographies -&gt; according to Monitoring war destruction from space using machine learning Hannes Mueller -&gt; the issue is train/test split is based on same cities and the accuracy results, if replicated in different cities (even if in the same country) tend to drop significantly. In this case, as explored by Ollie Ballinger, SAR radar imagery can be applied, as it has been presented on the example of Ukraine and Gaza war zones, where flat roof surface (rumbled or not) has been used to detect damaged buildings (possible thanks to changes in backscattering). This method allowed to replicate high accuracies across different cities in different countries. Limitations here: snow on the rooftops!\n\nExample 3 (reference https://www.intechopen.com/chapters/63701) Wetland Monitoring and Mapping Using Synthetic Aperture Radar Implementation of SAR imagery for water level monitoring, i.e. allows the evaluation of methane emission contributions to climate change from degraded and thawing wetlands. SAR is particularly useful in this case since it provides data regardless of weather conditions and lighting, and wetlands tend to be located in remote areas or under cloud cover.\nSoldiery applications\nships\n\nSAR has become one of the valued remote sensing tools for both soldierly and non-combatant users. Various soldierly SAR applications are intelligence gathering, battlefield survey, and weapons supervision. The non-combatant applications like agricultural and land-use monitoring, topographic planning, geology and mining, oil spill observation, sea ice observation, oceanography and planetary or celestial examinations [11]. SAR has wide practical applications on ocean as well as on land like artificial illegal or coincidental spills are visible in SAR images in the oceans, ships detection and tracking in the oceans, observation of natural leakage from oil deposits in the oceans, providing hints for the oil industries, ocean wave forecasting and marine climatology, regional ice monitoring. This is very crucial and helpful for navigation in ice-infested waters [11].\nSynthetic Aperture Radar. Available at: http://wtlab.iis.u-tokyo.ac.jp/~wataru/lecture/rsgis/rsnote/cp4/cp4-3.htm\nConversely, add some limitations https://link.springer.com/article/10.1007/s11831-021-09548-z"
  },
  {
    "objectID": "week9.html#reflection",
    "href": "week9.html#reflection",
    "title": "9  Week 9",
    "section": "9.3 Reflection",
    "text": "9.3 Reflection\nThis week I am especially amazed by the applications of SAR imagery both in soldierly and non-combatant uses. Its ability to provide a vast data in an affordable way allows for advanced analysis"
  },
  {
    "objectID": "week5.html#reflection",
    "href": "week5.html#reflection",
    "title": "5  Week 5",
    "section": "5.1 Reflection",
    "text": "5.1 Reflection\nNo entry required. See you next week!"
  },
  {
    "objectID": "week6.html",
    "href": "week6.html",
    "title": "6  Week 6",
    "section": "",
    "text": "7 Google Earth Engine"
  },
  {
    "objectID": "week7.html",
    "href": "week7.html",
    "title": "7  Week 7",
    "section": "",
    "text": "Classification I"
  },
  {
    "objectID": "week8.html",
    "href": "week8.html",
    "title": "8  Week 8",
    "section": "",
    "text": "Classification II"
  },
  {
    "objectID": "week9.html",
    "href": "week9.html",
    "title": "9  Week 9",
    "section": "",
    "text": "Synthetic Aperture Radar (SAR)"
  },
  {
    "objectID": "week9.html#references",
    "href": "week9.html#references",
    "title": "9  Week 9",
    "section": "9.5 References",
    "text": "9.5 References\nLee JS, Pottier E. Polarimetric Radar Imaging: From Basics to Applications. Boca Raton, FL, USA: CRC Press; 2009"
  },
  {
    "objectID": "week6.html#summary",
    "href": "week6.html#summary",
    "title": "6  Week 6",
    "section": "7.1 Summary",
    "text": "7.1 Summary\n\n7.1.1 What is it?\nGeospatial data processing & analysis cloud-based platform powered by Google; It hosts petabytes of over 40 years of remotely-sensed data, such as Landsat, MODIS, National Oceanographic and Atmospheric Administration Advanced Very High Resolution Radiometer (NOAA AVHRR), Sentinel 1, 2, 3 and 5-P; and Advanced Land Observing Satellite (ALOS) data. (Gorelick et al., 2017). MODIS collections for example, provide a twice a day global coverage. N. Gorelick et al. Google Earth Engine: Planetary-scale geospatial analysis for everyone\nGEE platform data is publicly available and is designed to be used with an explorer web app. It also provides various machine learning algorithms based on Google’s computational infrastructure and allows for high-speed parallel processing. In addition it provides library of APIs enabling the use of JavaScript and Python for analysis ((Tamiminia?) et al., 2020) https://www.sciencedirect.com/science/article/abs/pii/S0924271620300927\nThis tool enables for analysis and visualizing big geospatial data without access to supercomputer or specialized coding expertise (cool!)"
  },
  {
    "objectID": "week6.html#applications",
    "href": "week6.html#applications",
    "title": "6  Week 6",
    "section": "7.2 Applications",
    "text": "7.2 Applications\nOverall, the Google Earth Engine has a vast and growing presence across the current literature. It has found its applications in the analysis of many societal issues such as: deforestation, drought, disaster, disease, food security, water management, climate monitoring, and environmental protection, as pointed by Google Earth Engine: Planetary-scale geospatial analysis for everyone Gorelick, 2017). Remote sensing applications. GEE has shown its potential in disaster mapping. However, it can delve into: droughts [198,199], earthquakes [200], floods [201,202], fires [203,204], and landslides [205,206]. Likewise, environmental monitoring [207] and mangrove mapping [208] have become very important in recent years.\nSince GEE is a rather multidisciplinary tool with many applications, I will focus on one particular research that I found quite interesting, i.e. application for wetland mapping and monitoring using sentinel data. https://www.mdpi.com/2072-4292/13/20/4169 presents its methodology (Figure 1) using a combination of Sentinel-1 and Sentinel-2 images and the pixel-based Random Forest (RF) classifier within GEE. Wetland maps were generated with a 10-m spatial resolution which yielded Overall Accuracy and Kappa coefficient values of respectively, 97.98% and 0.97, which indicates the high efficiency of the proposed method in mapping of this ecosystem. It has been pointed that despite GEE offering a preprocessed data, the Sentinel-1 scenes included speckle noise, which has a negative impact on the classification results as it has been concluded by other studies (Adeli, S.; Salehi, B.; Mahdianpari, M.; Quackenbush, L.J.; Brisco, B.; Tamiminia, H.; Shaw, S. Wetland Monitoring Using SAR Data: A Meta-Analysis and Comprehensive Review. Remote Sens. 2020, 12, 2190. [Google Scholar] [CrossRef]). This signals as a reminder for further research to ensure pre-processing steps in their methodologies. This study proved to result in a time-saving and cost-efficient method of intensive field data collection, allowing to map and monitor important environmental changes.\n\n\n\nFigure 1. Methodology used in Wetland Monitoring Using SAR Data: A Meta-Analysis and Comprehensive Review(2020)\n\n\nConsidering the numerous advantages of Google Earth Engine, it is easy to forget about its negative externalities! As it has been noted by https://www.sciencedirect.com/science/article/pii/S0048969723072121 “A simple band arithmetic function applied to a Landsat 9 scene using Google Earth Engine (GEE) generated CO2 equivalent (e) emissions of 0.042–0.69 g CO2e (locally) and 0.13–0.45 g CO2e”. There have been many studies signaling that data centres are already producing CO2 emissions similar in a scale to emissions from aviation (Carbon footprint in data centre: A case study https://link.springer.com/article/10.1007/s11948-019-00171-7). I think this information should be treated as a motivation to seek more transparency from cloud services regarding their data life-cycle impacts, and the actual cost of cloud computation."
  },
  {
    "objectID": "week6.html#references",
    "href": "week6.html#references",
    "title": "6  Week 6",
    "section": "7.4 References",
    "text": "7.4 References\nhttps://www.sciencedirect.com/science/article/pii/S2352938522002154"
  },
  {
    "objectID": "week6.html#reflections",
    "href": "week6.html#reflections",
    "title": "6  Week 6",
    "section": "7.3 Reflections",
    "text": "7.3 Reflections\nThis week I guess I embedded some of the reflective notion within the part above as well. Nevertheless, it is extremely interesting to see the exponential increase in number of articles published regarding GEE. Availability of this data, even though it still requires expertise to use, has opened many opportunities for researches from around the world, and even hobbyists. This is a great step towards democratization of data access and distribution of power. Nevertheless, with great power comes great responsibility! As I mentioned earlier, all of the consequences need to be taken into account, e.g. carbon footprint (!), insufficient data centres’ environmental policies, etc. At the end of the day, there is no such thing as a free lunch."
  },
  {
    "objectID": "week7.html#summary",
    "href": "week7.html#summary",
    "title": "7  Week 7",
    "section": "7.1 Summary",
    "text": "7.1 Summary\nClassification refers to the process of categorizing pixels in satellite imagery into distinct classes or categories based on their spectral signatures, textural features, or other characteristics detectable from the imagery. This is in line with Tobler’s first law of geography, i.e. closer things are more related.\n\n7.1.1 How does it work?\nExpert Systems - a system that uses human knowledge to solve problems that require human intelligence, e.g. training datasets.\nMachine Learning\nIs linear regression machine learning? Yes, it can be considered so. Types of ML:\n- classification trees - classify data into two or more discrete categories, e.g. should I play golf today? - regression trees - predict continuous dependent variable, e.g. GCSE score\nOverfitting - too perfect model, 100% accuracy, most likely useless, e.g leaf with just one person or pixel value\nUnderfitting - potentially can happen when forcing a linear relationship in regression when out data in not linear.\n- random forests - produce bootstrap samples; many decision trees with less control (from a random numver of variables)\n- image classification: - unsupervised (pixels are grouped into “clusters” based on their properties, and each “cluster” is classified with a land cover class)\n\nsupervised (representative samples are chosen for each land cover class, and based on the training set results, this is replicated for the entire image)\nOBIA - object based image analysis (especially useful for high-resolution data because it uses both spectral and contextual information; pixels are grouped into representative vector shapes with size and geometry)\n\nInterestingly, higher resolution images do not guarantee better land cover. The image classification techniques used are a very important factor for better accuracy."
  },
  {
    "objectID": "week7.html#applications",
    "href": "week7.html#applications",
    "title": "7  Week 7",
    "section": "7.2 Applications",
    "text": "7.2 Applications\nThe goal of classification in environmental and Earth sciences is often to monitor changes over time, assess ecosystem health, plan conservation efforts, or understand human impact on natural landscapes, among other applications. In recent years, the use of deep learning in remote sensing image classification is becoming more and more popular, especially thanks to its powerful feature extraction capabilities and robustness (Shen et al., 2021). https://www.researchgate.net/publication/350370369_Remote_Sensing_Image_Classification_Using_Deep-Shallow_Learning\nBrazil case from lecture: Monitoring forests + illegal logging - instead of using the raw Earth observation data, they’re making composites, they’re taking part of the data that are most relevant for their application, so here we have maximum, minimum, mean values and some kind of linear regression also happening. And then from those metrics they are then using a classifier on the metrics as opposed to the raw Google data. Forest fires paper - vegetation was from a classified Landsat TM image - classified 16 categories.\nhttps://www.sciencedirect.com/science/article/abs/pii/S0168169923006154 - this study aims to develop a deep learning framework to improve the accuracy of crop type identification using Sentinel 2 data. Researchers built a time-series image classification framework using Attention-based Bidirectional Gated Recurrent Unit (A-BiGRU) to map rice, maize, and soybean in Fujin region of China, from reconstructed Sentinel-2 time-series images. Figure 1 demonstrates methodolgy used in this study. Interestingly, despite its the inherent disadvantage of CNNs is the need for a large number of spatially labeled samples.as it has been observed by Gallo et al. (2023) Nevertheless, different studies which focused on using a different algorithm, e.g. https://www.mdpi.com/2072-4292/15/13/3212 who used RF algorithm also on Sentinel 2 data, was able to achieve a significantly higher accuracy. Their study was based on random forest importance and normalization, which concluded in a strong performance for early crop mapping.\n\n\n\nFigure 1. Methodology used in A deep learning framework for crop mapping with reconstructed Sentinel-2 time series images (2021)"
  },
  {
    "objectID": "week7.html#reflections",
    "href": "week7.html#reflections",
    "title": "7  Week 7",
    "section": "7.3 Reflections",
    "text": "7.3 Reflections\nCase of Brazil forest monitoring was among the most thought provoking this week fir me. Fact that the area of a forest the size of Nepal can be monitored by two employees with two vehicles, a boat and a drone and provide a sufficient image within 20 minutes is just incredible, how efficient this is. At the same time, it is also a bit scary to think about its monitoring capabilities… is there a line between control, justice and big brother entering into our lives? At the same time, it is incredible how all of the image classification efforts (as in example from China) may result in tools able to predict crop yield and monitor its growth, indirectly ensuring food security. I found it interesting to find out about machine learning real use-cases. I’m quite amazed with its vast options and and seemingly endless opportunities for accuracy improvements."
  },
  {
    "objectID": "week8.html#summary",
    "href": "week8.html#summary",
    "title": "8  Week 8",
    "section": "8.1 Summary",
    "text": "8.1 Summary\nThis entry is a continuation of classification topic.\nThere are available sources of pre-classified data that can be used instead of producing own datasets: - GlobeLand30 - European Space Agency’s (ESA) Climate Change Initiative (CCI) - Dynamic World - near real time 10m - MODIS - Google building data\nDynamic World datasets are using semi-supervised approach - stratification based; trained with the expert group. Mapping unit is 5x5 pixels, therefore its limitation is that it can include various land uses. It is based on CNNs with accuracy assess through Confusion matrix. Training data available at Radiant MLHub.\nObject based image analysis (OBIA) - they are based on SLIC (Simple Lienar Iterative Clustering) Algorithm for Superpixel generation. It measure the distance from point to the centre of the pixel\nSub pixel analysis (aka Spectral Mixture Analysis) - identification of the composition of land cover types per single pixel; with the use of comparing our findings to the known spectrally pure endmembers; V-I-S triangle is used here\nAccuracy assessment - this process involves comparing the classified data against the actual data in order to determine how well it performs. Common metrics used in accuracy assessment include overall accuracy (OA), producer’s accuracy, user’s accuracy, errors of omission, errors of commission and the Kappa coefficient.\nSpatial cross validation - cross-validation techniques based on random split of the dataset into training and testing subsets. Crucial for models applied to geographic data because nearby observations are often more similar to each other than to distant observations, due to spatial autocorrelation."
  },
  {
    "objectID": "week8.html#applications",
    "href": "week8.html#applications",
    "title": "8  Week 8",
    "section": "8.2 Applications",
    "text": "8.2 Applications\nHighlighting innovative uses of image classification, such as detecting floating plastics in water bodies, the text showcases the expanding range of environmental issues that can be addressed. These applications not only demonstrate the versatility of image classification techniques but also underscore their potential in environmental protection and resource management.WOWO\nIn the study by https://link.springer.com/article/10.1007/s11069-022-05642-y thee classification methods were evaluated for the purpose of detecting co-seismic landslides in seismically active area in Lesser Himalaya in Pakistan. Maximum Likelihood Classification, OBIA, and COSI-Corr were analyzed for the purpose of identifying their accuracy levels and model reliability (Figure 1). It has been concluded that MLC classification technique is performing worse than other pixel-based landslide classification algorithms which is consistent with other existing literature ( Saba et al. 2019). COSI-Corr offered better outcome thanks to the sub-pixel analysis and employing extra masks for landslide detection. This has also been confirmed by Saba et al. (2017). However, as a consequence of natural variation and atmospheric effects, this method resulted in some extent of spleckled noise in pixels, which in consequence leads to spectral image being exhibited differently. Similar study by https://ieeexplore.ieee.org/abstract/document/9897214?casa_token=EzRUtojc9OMAAAAA:0Tn-vSMMikITkTbGg_b38bBfLskPYBxU8NdSTJjgml24m8azFeay4wRJUC8M84cFi6_JU3oA also explored this method for ground deformation study disregarding use of COSI-Corr for CNN-DATe which provided them with results of better accuracy. Back to the initial paper, third method OBIA’s performance was deemed as highly dependent on the spatial resolution of the imagery. “Although many studies (Moosavi et al. 2014; Sibaruddin et al. 2018; Saba et al. 2019) from around the world suggest that OBIA-based classification produces better landslide maps than pixel-based techniques, it still has a number of drawbacks that might be addressed through the use of COSI-Corr approach for co-seismic landslide identification. To improve these techniques for various Geosciences applications, particularly landslide detection (Debella-Gilo and Kääb 2011; Butler 2018), consistent efforts are required.”\n\n\n\nFigure 1. Comparison of classification techniques (yellow), i.e. a Pixel-based MLC, b Object–based and c COSI-Corr"
  },
  {
    "objectID": "week8.html#reflections",
    "href": "week8.html#reflections",
    "title": "8  Week 8",
    "section": "8.3 Reflections",
    "text": "8.3 Reflections\nRadiant MLHub might come very handy for my other machine learning projects I’m doing! To Kappa or not to Kappa"
  },
  {
    "objectID": "week9.html#song-of-the-week",
    "href": "week9.html#song-of-the-week",
    "title": "9  Week 9",
    "section": "9.4 Song of the week",
    "text": "9.4 Song of the week\nParanoid London"
  },
  {
    "objectID": "week8.html#references",
    "href": "week8.html#references",
    "title": "8  Week 8",
    "section": "8.4 References",
    "text": "8.4 References\nSaba SB, Khattak NU, Ali M, Waseem M, Siddiqui S, Anjum S, Turab SA (2019) Application of sub-pixel-based technique “orthorectification of optically sensed images and its correlation” for co-seismic landslide detection and its accuracy modification through integration of various masks. J Himalayan Earth Sci 51:37–50 Saba SB, Ali M, van der Meijde M, van der Werff H (2017) Co-seismic landslides automatic detection on regional scale with sub-pixel analysis of multi temporal high resolution optical images: Application to southwest of Port au Prince, Haiti. J Himalayan Earth Sci 50:74–92"
  }
]